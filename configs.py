"""Record of config settings for reported experiments and retrievel."""


def get_config(experiment_name):
    if experiment_name == 't2048fwcomp':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't2048fwcomp',
            'batch_size': 16,
            'transfer_name': 'e2048',
            'sos_eos': True,
            'encoder_size': 2048,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'comp',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.002,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 'r2048fwcomp':
        return {
        'tune_target': 'dev-full',
        'bidirectional': True,
        'projection_size': 200,
        'p_drop': 0.1,
        'collator': 'rnn_sent',
        'lr_decay_rate': 0.2,
        'tune_embeds': False,
        'name': 'r2048fwcomp',
        'batch_size': 16,
        'transfer_name': 'e2048',
        'sos_eos': True,
        'encoder_size': 2048,
        'stop_lr_lim': 1e-05,
        'emb_lr_factor': 0.01,
        'encoder': 'lstm',
        'encoder_layers': 1,
        'grid_name': '',
        'model': 'comp',
        'target': 'train-full',
        'tune_encoder': True,
        'l2': 0.0,
        'max_epochs': 200,
        'from_grid_trans': False,
        'stop_t_worse': 1,
        'transfer': False,
        'lr_decay_every': 0.0,
        'seed': -1,
        'tokenizer': 'spacy',
        'hidden_size': 512,
        'embed_type': 'glove',
        'lr': 0.002,
        'lr_decay_grace': 0,
        'embed_size': 300,
        'n_runs': 20,
        'p_drop_rnn': 0.0,
        'stopping': 'min_lr',
        'annealing': 'tune_acc_decay',
        'enc_lr_factor': 1.0,
        'override': True,
        'from_grid': False,
    }

    elif experiment_name == 't1024fwcomp':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't1024fwcomp',
            'batch_size': 16,
            'transfer_name': 'e1024',
            'sos_eos': True,
            'encoder_size': 1024,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'comp',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.004,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 'r1024fwcomp':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 'r1024fwcomp',
            'batch_size': 16,
            'transfer_name': 'e1024',
            'sos_eos': True,
            'encoder_size': 1024,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'comp',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': False,
            'stop_t_worse': 1,
            'transfer': False,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.004,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't512fwcomp':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't512fwcomp',
            'batch_size': 16,
            'transfer_name': 'e512',
            'sos_eos': True,
            'encoder_size': 512,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'comp',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.003,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 1,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't512fwcompN':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't512fwcompN',
            'batch_size': 16,
            'transfer_name': 'e512',
            'sos_eos': True,
            'encoder_size': 512,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'comp',
            'target': 'negs',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.003,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 'r512fwcomp':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 'r512fwcomp',
            'batch_size': 16,
            'transfer_name': 'e512',
            'sos_eos': True,
            'encoder_size': 512,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'comp',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': False,
            'stop_t_worse': 1,
            'transfer': False,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.003,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't300fwcomp':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't300fwcomp',
            'batch_size': 16,
            'transfer_name': 'e300',
            'sos_eos': True,
            'encoder_size': 300,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'comp',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.002,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 1,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 'r300fwcomp':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 'r300fwcomp',
            'batch_size': 16,
            'transfer_name': 'e300',
            'sos_eos': True,
            'encoder_size': 300,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'comp',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': False,
            'stop_t_worse': 1,
            'transfer': False,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.002,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 19,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't100fwcomp':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't100fwcomp',
            'batch_size': 16,
            'transfer_name': 'e100',
            'sos_eos': True,
            'encoder_size': 100,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'comp',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.003,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 'r100fwcomp':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 'r100fwcomp',
            'batch_size': 16,
            'transfer_name': 'e100',
            'sos_eos': True,
            'encoder_size': 100,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'comp',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': False,
            'stop_t_worse': 1,
            'transfer': False,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.003,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't512fwcompc':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't512fwcompc',
            'batch_size': 16,
            'transfer_name': 'e512',
            'sos_eos': True,
            'encoder_size': 512,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.1,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'compc',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.002,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't512fwcompcHalf':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't512fwcompcHalf',
            'batch_size': 16,
            'transfer_name': 'e512',
            'sos_eos': True,
            'encoder_size': 512,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.1,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'compc',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.002,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't512fwcompcN':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't512fwcompcN',
            'batch_size': 16,
            'transfer_name': 'e512',
            'sos_eos': True,
            'encoder_size': 512,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.1,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'compc',
            'target': 'negs',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.002,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't640fwcomprw2':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't640fwcomprw2',
            'batch_size': 16,
            'transfer_name': 'e640',
            'sos_eos': True,
            'encoder_size': 640,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'comprw2',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.006,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't2048fwlin':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't2048fwlin',
            'batch_size': 16,
            'transfer_name': 'e2048',
            'sos_eos': True,
            'encoder_size': 2048,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'lin',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.002,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 'r2048fwlin':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 'r2048fwlin',
            'batch_size': 16,
            'transfer_name': 'e2048',
            'sos_eos': True,
            'encoder_size': 2048,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'lin',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': False,
            'stop_t_worse': 1,
            'transfer': False,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.003,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't1024fwlin':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't1024fwlin',
            'batch_size': 16,
            'transfer_name': 'e1024',
            'sos_eos': True,
            'encoder_size': 1024,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'lin',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.003,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 'r1024fwlin':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 'r1024fwlin',
            'batch_size': 16,
            'transfer_name': 'e1024',
            'sos_eos': True,
            'encoder_size': 1024,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'lin',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': False,
            'stop_t_worse': 1,
            'transfer': False,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.003,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't512fwlin':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't512fwlin',
            'batch_size': 16,
            'transfer_name': 'e512',
            'sos_eos': True,
            'encoder_size': 512,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'lin',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.02,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 'r512fwlin':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 'r512fwlin',
            'batch_size': 16,
            'transfer_name': 'e512',
            'sos_eos': True,
            'encoder_size': 512,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'lin',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': False,
            'stop_t_worse': 1,
            'transfer': False,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.02,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't300fwlin':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't300fwlin',
            'batch_size': 16,
            'transfer_name': 'e300',
            'sos_eos': True,
            'encoder_size': 300,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'lin',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.02,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 'r300fwlin':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 'r300fwlin',
            'batch_size': 16,
            'transfer_name': 'e300',
            'sos_eos': True,
            'encoder_size': 300,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'lin',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': False,
            'stop_t_worse': 1,
            'transfer': False,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.02,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 't100fwlin':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 't100fwlin',
            'batch_size': 16,
            'transfer_name': 'e100',
            'sos_eos': True,
            'encoder_size': 100,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'lin',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': True,
            'stop_t_worse': 1,
            'transfer': True,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.2,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    elif experiment_name == 'r100fwlin':
        return {
            'tune_target': 'dev-full',
            'bidirectional': True,
            'projection_size': 200,
            'p_drop': 0.1,
            'collator': 'rnn_sent',
            'lr_decay_rate': 0.2,
            'tune_embeds': False,
            'name': 'r100fwlin',
            'batch_size': 16,
            'transfer_name': 'e100',
            'sos_eos': True,
            'encoder_size': 100,
            'stop_lr_lim': 1e-05,
            'emb_lr_factor': 0.01,
            'encoder': 'lstm',
            'encoder_layers': 1,
            'grid_name': '',
            'model': 'lin',
            'target': 'train-full',
            'tune_encoder': True,
            'l2': 0.0,
            'max_epochs': 200,
            'from_grid_trans': False,
            'stop_t_worse': 1,
            'transfer': False,
            'lr_decay_every': 0.0,
            'seed': -1,
            'tokenizer': 'spacy',
            'hidden_size': 512,
            'embed_type': 'glove',
            'lr': 0.2,
            'lr_decay_grace': 0,
            'embed_size': 300,
            'n_runs': 20,
            'p_drop_rnn': 0.0,
            'stopping': 'min_lr',
            'annealing': 'tune_acc_decay',
            'enc_lr_factor': 1.0,
            'override': True,
            'from_grid': False,
        }

    else:
        raise ValueError('Unexpexted experiment_name: %s' % experiment_name)
